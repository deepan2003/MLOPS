# This is the final, corrected CI/CD pipeline.
# It uses a single requirements.txt file to ensure all versions are correct.

name: ðŸ¥ Heart Attack MLOps Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.9'

jobs:
  dvc-pipeline:
    name: ðŸ”„ DVC ML Pipeline (Preprocess & Train)
    runs-on: ubuntu-latest
    outputs:
      model-changed: ${{ steps.check-changes.outputs.model-changed }}

    steps:
    - name: ðŸ“¥ Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: ðŸ Setup Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: ðŸ“¦ Install All Dependencies
      # CORRECTED: Removed the conflicting "pip install dvc[s3]" line.
      # Now, it will only use your requirements.txt file.
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: ðŸ” Configure DVC S3 Remote
      run: |
        dvc remote modify s3remote endpointurl https://play.min.io
        dvc remote default s3remote

    - name: ðŸ“Š Pull Latest Data from Remote
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      run: dvc pull

    - name: ðŸš€ Execute DVC Pipeline (Reproduce Model)
      run: dvc repro

    - name: ðŸ“ˆ Display Model Metrics in Summary
      run: |
        echo "## ðŸ“Š Heart Attack Model Performance" >> $GITHUB_STEP_SUMMARY
        dvc metrics show --md >> $GITHUB_STEP_SUMMARY

    - name: ðŸ” Check for Model Changes
      id: check-changes
      run: |
        if git diff --quiet HEAD^ HEAD -- models/ || [ ! -d models ]; then
          echo "model-changed=false" >> $GITHUB_OUTPUT
        else
          echo "model-changed=true" >> $GITHUB_OUTPUT
        fi

    - name: ðŸ“¤ Upload Data to Remote Storage
      if: github.ref == 'refs/heads/main'
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      run: dvc push

    - name: ðŸ“¦ Save Model Artifacts for Next Job
      uses: actions/upload-artifact@v4
      with:
        name: trained-model-artifacts
        path: |
          models/
          data/preprocessed/
          metrics.json
        retention-days: 7

  quality-assurance:
    name: ðŸ§ª Quality Assurance (Tox)
    runs-on: ubuntu-latest
    needs: dvc-pipeline
    strategy:
      fail-fast: false
      matrix:
        tox-env: [py39, lint, security]
    steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    - name: ðŸ“¦ Download Model Artifacts
      uses: actions/download-artifact@v4
      with:
        name: trained-model-artifacts
    - name: ðŸ“¦ Install Dependencies
      run: pip install -r requirements.txt
    - name: ðŸ§ª Run Tox Environment
      run: tox -e ${{ matrix.tox-env }}

  deploy-to-render:
    name: "ðŸš€ Deploy to Production (Render)"
    runs-on: ubuntu-latest
    needs: [dvc-pipeline, quality-assurance]
    if: github.ref == 'refs/heads/main' && needs.dvc-pipeline.outputs.model-changed == 'true'
    steps:
    - name: "ðŸš€ Trigger Render Deploy"
      run: curl -X POST ${{ secrets.RENDER_DEPLOY_HOOK }}