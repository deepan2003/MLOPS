# This is the final, corrected CI/CD pipeline.
# It uses the direct studio.datachain.ai URL and fixes the quality-assurance job.

name: ğŸ¥ Heart Attack MLOps Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.9'

jobs:
  dvc-pipeline:
    name: ğŸ”„ DVC ML Pipeline (Preprocess & Train)
    runs-on: ubuntu-latest
    outputs:
      model-changed: ${{ steps.check-changes.outputs.model-changed }}

    steps:
    - name: ğŸ“¥ Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: ğŸ Setup Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: ğŸ“¦ Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install dvc
        pip install -r requirements.txt

    - name: ğŸ” Configure DVC Studio Remote
      env:
        DVC_STUDIO_TOKEN: ${{ secrets.DVC_STUDIO_TOKEN }}
        DVC_STUDIO_USERNAME: ${{ secrets.DVC_STUDIO_USERNAME }}
      run: |
        dvc remote add studio https://studio.datachain.ai/api/dvc/$DVC_STUDIO_USERNAME/heart-attack-project --force
        dvc remote modify studio --local auth basic
        dvc remote modify studio --local user $DVC_STUDIO_USERNAME
        dvc remote modify studio --local password $DVC_STUDIO_TOKEN
        dvc remote default studio

    - name: ğŸ“Š Pull Latest Data from Remote
      run: dvc pull

    - name: ğŸš€ Execute DVC Pipeline (Reproduce Model)
      run: dvc repro

    - name: ğŸ“ˆ Display Model Metrics in Summary
      run: |
        echo "## ğŸ“Š Heart Attack Model Performance" >> $GITHUB_STEP_SUMMARY
        dvc metrics show --md >> $GITHUB_STEP_SUMMARY

    - name: ğŸ” Check for Model Changes
      id: check-changes
      run: |
        if git diff --quiet HEAD^ HEAD -- models/ || [ ! -d models ]; then
          echo "model-changed=false" >> $GITHUB_OUTPUT
        else
          echo "model-changed=true" >> $GITHUB_OUTPUT
        fi

    - name: ğŸ“¤ Upload Data to Remote Storage
      if: github.ref == 'refs/heads/main'
      run: dvc push

    - name: ğŸ“¦ Save Model Artifacts for Next Job
      uses: actions/upload-artifact@v4
      with:
        name: trained-model-artifacts
        path: |
          models/
          data/preprocessed/
          metrics.json
        retention-days: 7

  quality-assurance:
    name: ğŸ§ª Quality Assurance (Tox)
    runs-on: ubuntu-latest
    needs: dvc-pipeline # This job runs after the dvc-pipeline job

    strategy:
      fail-fast: false
      matrix:
        tox-env: [py39, lint, security]
    steps:
    - name: ğŸ“¥ Checkout Code
      uses: actions/checkout@v4

    - name: ğŸ Setup Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: ğŸ“¦ Download Model Artifacts from Previous Job
      # FIXED: Added this step to get the model and data files
      uses: actions/download-artifact@v4
      with:
        name: trained-model-artifacts
        # This will download the files into the correct folders (models/, data/preprocessed/)

    - name: ğŸ“¦ Install Dependencies
      # FIXED: Added this step to install pytest, pandas, etc.
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install tox

    - name: ğŸ§ª Run Tox Environment [${{ matrix.tox-env }}]
      run: tox -e ${{ matrix.tox-env }}

  deploy-to-render:
    name: "ğŸš€ Deploy to Production (Render)"
    runs-on: ubuntu-latest
    needs: [dvc-pipeline, quality-assurance] # Runs after both previous jobs succeed
    if: github.ref == 'refs/heads/main' && needs.dvc-pipeline.outputs.model-changed == 'true'
    steps:
    - name: "ğŸš€ Trigger Render Deploy"
      run: curl -X POST ${{ secrets.RENDER_DEPLOY_HOOK }}

